{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a55e451d",
   "metadata": {},
   "source": [
    "# Prophecy paper example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e9f345",
   "metadata": {},
   "source": [
    "### 1. Pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee958236",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07863fe9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# device = (\n",
    "#   \"cuda\"\n",
    "#   if torch.cuda.is_available()\n",
    "#   else \"mps\"\n",
    "#   if torch.backends.mps.is_available()\n",
    "#   else \"cpu\"\n",
    "# )\n",
    "# print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ade2e556",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ProphecyExampleNetwork(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.flatten = nn.Flatten()    \n",
    "    self.linear_relu_stack = nn.Sequential(\n",
    "      nn.Linear(2, 2, bias=False), # First hidden layer, with relu activation\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(2, 2, bias=False), # Second hidden layer, with relu activation \n",
    "      nn.ReLU(),\n",
    "    )\n",
    "    self.final_output = nn.Linear(2, 2, bias=False)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.flatten(x)\n",
    "    relu_stack_outputs = self.linear_relu_stack(x)\n",
    "    logits = self.final_output(relu_stack_outputs)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "499715cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProphecyExampleNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=2, out_features=2, bias=False)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (final_output): Linear(in_features=2, out_features=2, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = ProphecyExampleNetwork()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "226a5ba7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set weight of each layer to be the same as in the paper\n",
    "with torch.no_grad():\n",
    "  model.linear_relu_stack[0].weight = nn.Parameter(torch.tensor([[1.0, -1.0], [1.0, 1.0]], dtype=torch.float))\n",
    "  model.linear_relu_stack[2].weight = nn.Parameter(torch.tensor([[0.5, -0.2], [-0.5, 0.1]], dtype=torch.float))\n",
    "  model.final_output.weight = nn.Parameter(torch.tensor([[1.0, -1.0], [-1.0, 1.0]], dtype=torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48e3acda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1., -1.]], grad_fn=<MmBackward0>)\n",
      "Predicted class: tensor([0])\n",
      "tensor([[ 2., -2.]], grad_fn=<MmBackward0>)\n",
      "Predicted class: tensor([0])\n"
     ]
    }
   ],
   "source": [
    "# test example input provided in paper background section\n",
    "input_data = [[1,-1]]\n",
    "X = torch.tensor(input_data, dtype=torch.float)\n",
    "logits = model(X)\n",
    "print(logits)\n",
    "prediction_prob = nn.Softmax(dim=1)(logits)\n",
    "y_pred = prediction_prob.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")\n",
    "\n",
    "# test example input [1, -3], which will yield [2, -2]\n",
    "input_data = [[1,-3]]\n",
    "X = torch.tensor(input_data, dtype=torch.float)\n",
    "logits = model(X)\n",
    "print(logits)\n",
    "prediction_prob = nn.Softmax(dim=1)(logits)\n",
    "y_pred = prediction_prob.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8461fc0b",
   "metadata": {},
   "source": [
    "### 2. Forward hook to get activation signatures in hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e2eb79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = {}\n",
    "def get_relu_activation(name):\n",
    "  def hook(model, inputs, outputs):\n",
    "    activation_signature = [\"ON\" if val > 0 else \"OFF\" for val in outputs[0]]\n",
    "    activation[name] = activation_signature\n",
    "  return hook\n",
    "\n",
    "# keep track of handles so that we can remove hooks later \n",
    "# (by calling handle.remove() for each handle in handles)\n",
    "relu_handles = []\n",
    "for idx, layer in enumerate(model.linear_relu_stack):\n",
    "  if isinstance(layer, torch.nn.ReLU):\n",
    "    handle = layer.register_forward_hook(get_relu_activation(idx))\n",
    "    relu_handles.append(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d4a2319",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_outputs = {}\n",
    "def get_layer_outputs(name):\n",
    "  def hook(model, inputs, outputs):\n",
    "    layer_outputs[name] = outputs.detach()\n",
    "  return hook\n",
    "\n",
    "layer_output_handles = []\n",
    "for idx, layer in enumerate(model.linear_relu_stack):\n",
    "  handle = layer.register_forward_hook(get_layer_outputs(idx))\n",
    "  layer_output_handles.append(handle)\n",
    "\n",
    "handle = model.final_output.register_forward_hook(get_layer_outputs(\"final_output\"))\n",
    "layer_output_handles.append(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c3414da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([0])\n",
      "{1: ['ON', 'OFF'], 3: ['ON', 'OFF']}\n",
      "{0: tensor([[2., 0.]]), 1: tensor([[2., 0.]]), 2: tensor([[ 1., -1.]]), 3: tensor([[1., 0.]]), 'final_output': tensor([[ 1., -1.]])}\n"
     ]
    }
   ],
   "source": [
    "# forward pass -- getting the outputs\n",
    "# input_data = [[1,-1]]\n",
    "input_data = [[1, -1.0]]\n",
    "X = torch.tensor(input_data, dtype=torch.float)\n",
    "logits = model(X)\n",
    "prediction_prob = nn.Softmax(dim=1)(logits)\n",
    "y_pred = prediction_prob.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")\n",
    "print(activation)\n",
    "print(layer_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b810518",
   "metadata": {},
   "source": [
    "### 3. Use MarabouCore as Decision Procedure (DP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94cbd0a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/khoanguyen-cp/anaconda3/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "sys.path.append('/Users/khoanguyen-cp/gmu/Marabou')\n",
    "\n",
    "from maraboupy import Marabou\n",
    "from maraboupy import MarabouCore\n",
    "from maraboupy.Marabou import createOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b1f29f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: ['ON', 'OFF'], 3: ['ON', 'OFF']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbc20496",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: tensor([[2., 0.]]),\n",
       " 1: tensor([[2., 0.]]),\n",
       " 2: tensor([[ 1., -1.]]),\n",
       " 3: tensor([[1., 0.]]),\n",
       " 'final_output': tensor([[ 1., -1.]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30cd334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_boundary_for_relu_vars(relu_vars, layer_activations, inputQuery):\n",
    "  for idx, var in enumerate(relu_vars):\n",
    "    if layer_activations[idx] == \"ON\": # var > 0\n",
    "      inputQuery.setLowerBound(var, 1e-6)\n",
    "      inputQuery.setUpperBound(var, 100)\n",
    "      \n",
    "    elif layer_activations[idx] == \"OFF\":\n",
    "      inputQuery.setLowerBound(var, 0)\n",
    "      inputQuery.setUpperBound(var, 0)\n",
    "      \n",
    "    else: # neuron is unconstrained, can be on or off\n",
    "      inputQuery.setLowerBound(var, 0)\n",
    "      inputQuery.setUpperBound(var, 100)\n",
    "      \n",
    "  return inputQuery\n",
    "      \n",
    "  \n",
    "def set_boundary_for_linear_vars(linear_vars, inputQuery):\n",
    "  for var in linear_vars:\n",
    "    inputQuery.setLowerBound(var, -100)\n",
    "    inputQuery.setUpperBound(var, 100)\n",
    "  return inputQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d41821f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_linear_constraints(layer_vars, layer, inputQuery):\n",
    "  # in dense layers, each neuron is connected to every neuron in the preceding layer\n",
    "  # we can check the current layer's in_features to see the size of the preceding layer\n",
    "  prev_layer_vars = list(range(layer.out_features - layer.in_features, layer.in_features))\n",
    "  \n",
    "  # Ex: x2 = w0*x0 + w1*x1 + b\n",
    "  # <=> w0*x0 + w1*x1 - x2 = -b\n",
    "  for idx, var in enumerate(layer_vars):\n",
    "    coefficients = layer.weight[idx]\n",
    "    equation = MarabouCore.Equation()\n",
    "    equation.addAddend(-1, var)\n",
    "    for prev_idx, prev_var in enumerate(prev_layer_vars):\n",
    "      equation.addAddend(coefficients[prev_idx], prev_var)\n",
    "      \n",
    "    scalar = 0.0 if layer.bias == None else (-layer.bias)\n",
    "    equation.setScalar(scalar)\n",
    "    inputQuery.addEquation(equation)\n",
    "      \n",
    "  return inputQuery\n",
    "\n",
    "\n",
    "def set_relu_constraints(relu_vars, inputQuery):\n",
    "  # each relu step is accompanied by a preceding linear layer of the same size\n",
    "  linear_vars = [var - len(relu_vars) for var in relu_vars]\n",
    "  for idx, relu_var in enumerate(relu_vars):\n",
    "    corresponding_linear_var = linear_vars[idx]\n",
    "    MarabouCore.addReluConstraint(inputQuery, corresponding_linear_var, relu_var)\n",
    "  return inputQuery\n",
    "\n",
    "\n",
    "def set_classification_constraints(layer_vars, layer, classification, inputQuery):\n",
    "  # Create disjunction pairs for classification_var and other vars in the output layer\n",
    "  classification_var = layer_vars[classification]\n",
    "  disjunction = []\n",
    "  for var in layer_vars: \n",
    "    if var == classification_var: continue\n",
    "    equation_type = MarabouCore.Equation.EquationType(2) # type 2 is Less than or equal (LE inequality)\n",
    "    equation = MarabouCore.Equation(equation_type) \n",
    "    equation.addAddend(1, classification_var)\n",
    "    equation.addAddend(-1, var)\n",
    "    equation.setScalar(0)\n",
    "    disjunction.append([equation])\n",
    "    \n",
    "  MarabouCore.addDisjunctionConstraint(inputQuery, disjunction)\n",
    "  return inputQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "261e8acf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For now, only supports postconditions that are network outputs being a particular class\n",
    "def dp(network_activations, model, postcondition):\n",
    "  num_of_vars = 0\n",
    "  inputQuery = MarabouCore.InputQuery()\n",
    "  \n",
    "  # INPUT CONSTRAINTS\n",
    "  # Input layer isn't part of the network, so we'll use the first layer's in_features\n",
    "  input_features = list(range(0, model.linear_relu_stack[0].in_features))\n",
    "  num_of_vars += len(input_features)\n",
    "  # print(f\"input: {input_features}\")\n",
    "  inputQuery.setNumberOfVariables(num_of_vars)\n",
    "  inputQuery = set_boundary_for_linear_vars(input_features, inputQuery)\n",
    "  \n",
    "  # HIDDEN LAYER CONSTRAINTS\n",
    "  for relu_layer_idx, activation_values in network_activations.items():\n",
    "    # each relu step is accompanied by a preceding linear layer of the same size\n",
    "    relu_layer = model.linear_relu_stack[relu_layer_idx]\n",
    "    linear_layer = model.linear_relu_stack[relu_layer_idx - 1]\n",
    "    \n",
    "    # constraints for linear layer\n",
    "    linear_vars = list(range(num_of_vars, num_of_vars + linear_layer.out_features))\n",
    "    num_of_vars += linear_layer.out_features\n",
    "    # print(f\"linear: {linear_vars}\")\n",
    "    inputQuery.setNumberOfVariables(num_of_vars)\n",
    "    inputQuery = set_boundary_for_linear_vars(linear_vars, inputQuery)\n",
    "    inputQuery = set_linear_constraints(linear_vars, linear_layer, inputQuery)\n",
    "    \n",
    "    # constraints for relu layer\n",
    "    relu_vars = list(range(num_of_vars, num_of_vars + linear_layer.out_features))\n",
    "    num_of_vars += linear_layer.out_features\n",
    "    # print(f\"relu: {relu_vars}\")\n",
    "    inputQuery.setNumberOfVariables(num_of_vars)\n",
    "    inputQuery = set_boundary_for_relu_vars(relu_vars, activation_values, inputQuery)\n",
    "    inputQuery = set_relu_constraints(relu_vars, inputQuery)\n",
    "    \n",
    "  # OUTPUT CONSTRAINTS \n",
    "  # if we want to check for postcondition of a class, we have to encode its inverse.\n",
    "  # Ex: given 3 classes, y1, y2, y3. If postcondition is y1, then we have to encode y != y1, i.e. y1 <= y2 or y1 <= y3.\n",
    "  layer = model.final_output\n",
    "  layer_vars = list(range(num_of_vars, num_of_vars + layer.out_features))\n",
    "  num_of_vars += layer.out_features\n",
    "  # print(f\"output: {layer_vars}\")\n",
    "  \n",
    "  inputQuery.setNumberOfVariables(num_of_vars)\n",
    "  inputQuery = set_boundary_for_linear_vars(layer_vars, inputQuery)\n",
    "  inputQuery = set_linear_constraints(layer_vars, layer, inputQuery)\n",
    "  inputQuery = set_classification_constraints(layer_vars, layer, postcondition, inputQuery)\n",
    "  \n",
    "  ## Run Marabou to solve the query\n",
    "  # print(\"solving with Marabou...\")\n",
    "  options = createOptions(verbosity=0)\n",
    "  return MarabouCore.solve(inputQuery, options, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d41bcfc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('unsat', {}, <maraboupy.MarabouCore.Statistics at 0x293202d30>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation = {1: ['ON', 'OFF'], 3: ['ON', 'OFF']}\n",
    "dp(activation, model, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf675c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sat',\n",
       " {0: -0.0,\n",
       "  1: -100.0,\n",
       "  2: 100.0,\n",
       "  3: -100.0,\n",
       "  4: 100.0,\n",
       "  5: 0.0,\n",
       "  6: 20.000000298023224,\n",
       "  7: -10.000000149011612,\n",
       "  8: 20.000000298023224,\n",
       "  9: 0.0,\n",
       "  10: 100.0,\n",
       "  11: -100.0},\n",
       " <maraboupy.MarabouCore.Statistics at 0x293202630>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp(activation, model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f8c8abc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('unsat', {}, <maraboupy.MarabouCore.Statistics at 0x29320df30>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_activation = {1: ['ON', '--'], 3: ['--', '--']}\n",
    "dp(new_activation, model, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "140e03bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([0])\n"
     ]
    }
   ],
   "source": [
    "input_data = [[0.0, -100.0]]\n",
    "X = torch.tensor(input_data, dtype=torch.float)\n",
    "logits = model(X)\n",
    "prediction_prob = nn.Softmax(dim=1)(logits)\n",
    "y_pred = prediction_prob.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3690e209",
   "metadata": {},
   "source": [
    "### 4. Iterative Relaxation Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36d6cd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prophecy_example_model():\n",
    "  model = ProphecyExampleNetwork()\n",
    "  # set weight of each layer to be the same as the Prophecy paper\n",
    "  with torch.no_grad():\n",
    "    model.linear_relu_stack[0].weight = nn.Parameter(torch.tensor([[1.0, -1.0], [1.0, 1.0]], dtype=torch.float))\n",
    "    model.linear_relu_stack[2].weight = nn.Parameter(torch.tensor([[0.5, -0.2], [-0.5, 0.1]], dtype=torch.float))\n",
    "    model.final_output.weight = nn.Parameter(torch.tensor([[1.0, -1.0], [-1.0, 1.0]], dtype=torch.float))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07272003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hooks\n",
    "def relu_activation_hook(layer_name, result_storage):\n",
    "  def hook(model, inputs, outputs):\n",
    "    result_storage[layer_name] = [\"ON\" if val > 0 else \"OFF\" for val in outputs[0]]\n",
    "  return hook\n",
    "\n",
    "def layer_output_hook(layer_name, result_storage):\n",
    "  def hook(model, inputs, outputs):\n",
    "    result_storage[layer_name] = outputs.detach()\n",
    "  return hook\n",
    "\n",
    "# hook attachers\n",
    "def attach_relu_activation_hook_to_model(model):\n",
    "  handles = []\n",
    "  activation_storage = {}\n",
    "  for idx, layer in enumerate(model.linear_relu_stack):\n",
    "    if isinstance(layer, torch.nn.ReLU):\n",
    "      handle = layer.register_forward_hook(relu_activation_hook(idx, activation_storage))\n",
    "      handles.append(handle)\n",
    "  return handles, activation_storage\n",
    "\n",
    "\n",
    "def attach_layer_output_hook_to_model(model):\n",
    "  handles = []\n",
    "  output_storage = {}\n",
    "  for idx, layer in enumerate(model.linear_relu_stack):\n",
    "    handle = layer.register_forward_hook(layer_output_hook(idx, output_storage))\n",
    "    handles.append(handle)\n",
    "  handle = model.final_output.register_forward_hook(layer_output_hook(\"final_output\", output_storage))\n",
    "  handles.append(handle)\n",
    "  return handles, output_storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c72c116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def iterative_relaxation(model, input_data, postcondition):\n",
    "  # attach hooks to model to get activation signature of X\n",
    "  _act_handles, activation_signature = attach_relu_activation_hook_to_model(model)\n",
    "  _out_handles, layer_outputs = attach_layer_output_hook_to_model(model)\n",
    "  \n",
    "  # evaluate model with X to get activation signature of X\n",
    "  X = torch.tensor(input_data, dtype=torch.float)\n",
    "  logits = model(X)\n",
    "  \n",
    "  status, _, __ = dp(activation_signature, model, postcondition)\n",
    "  if status == \"sat\":\n",
    "    return [activation_signature, postcondition]\n",
    "  \n",
    "  layer_indices = sorted(activation_signature.keys())\n",
    "  # print(f\"layer indices: {layer_indices}\")\n",
    "  unconstrained_layer_idx = layer_indices.pop()\n",
    "  \n",
    "  while unconstrained_layer_idx > 0: \n",
    "    print(f\"unconstrained_layer_id: {unconstrained_layer_idx}\")\n",
    "    \n",
    "    # unconstrain all neurons in the layer\n",
    "    original_activation = activation_signature[unconstrained_layer_idx]\n",
    "    activation_signature[unconstrained_layer_idx] = [\"--\" for val in original_activation]\n",
    "    print(activation_signature)\n",
    "    \n",
    "    status, _, __ = dp(activation_signature, model, postcondition)\n",
    "    \n",
    "    if status == \"sat\": # critical layer found\n",
    "      print(f\"Critical layer found: {unconstrained_layer_idx}\")\n",
    "      \n",
    "      crit_layer_idx = unconstrained_layer_idx\n",
    "      # add back activations from critical layer\n",
    "      activation_signature[crit_layer_idx] = copy.deepcopy(original_activation)\n",
    "      crit_layer_activation = activation_signature[crit_layer_idx]\n",
    "      \n",
    "      # iteratively unconstrain neurons to see if they are needed\n",
    "      for neuron_idx, _val in enumerate(activation_signature[crit_layer_idx]):\n",
    "        crit_layer_activation[neuron_idx] = \"--\"\n",
    "        # print(f\"--- unconstraining neuron {neuron_idx} in critical layer\")\n",
    "        # print(activation_signature)\n",
    "        status, _, __ = dp(activation_signature, model, postcondition)\n",
    "        \n",
    "        if status == \"sat\": # neuron needed, must remain constrained\n",
    "          # print(f\"--- neuron needed\")\n",
    "          crit_layer_activation[neuron_idx] = original_activation[neuron_idx]\n",
    "      \n",
    "      return [activation_signature]\n",
    "    \n",
    "    else: \n",
    "      unconstrained_layer_idx = layer_indices.pop()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a81bed64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unconstrained_layer_id: 3\n",
      "{1: ['ON', 'OFF'], 3: ['--', '--']}\n",
      "unconstrained_layer_id: 1\n",
      "{1: ['--', '--'], 3: ['--', '--']}\n",
      "Critical layer found: 1\n",
      "input property: [{1: ['ON', '--'], 3: ['--', '--']}]\n"
     ]
    }
   ],
   "source": [
    "test_model = create_prophecy_example_model()\n",
    "input_property = iterative_relaxation(test_model, [[1, -1]], 0)\n",
    "print(f\"input property: {input_property}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8322be79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('unsat', {}, <maraboupy.MarabouCore.Statistics at 0x293203330>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model = create_prophecy_example_model()\n",
    "activation = {1: ['ON', '--'], 3: ['--', '--']}\n",
    "dp(activation, eval_model, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc0eb65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([1])\n",
      "{0: tensor([[1., 7.]]), 1: tensor([[1., 7.]]), 2: tensor([[-0.9000,  0.2000]]), 3: tensor([[0.0000, 0.2000]]), 'final_output': tensor([[-0.2000,  0.2000]])}\n",
      "{1: ['ON', 'ON'], 3: ['OFF', 'ON']}\n"
     ]
    }
   ],
   "source": [
    "input_data = [[4.0, 3.0]]\n",
    "X = torch.tensor(input_data, dtype=torch.float)\n",
    "_out_handles, layer_outputs = attach_layer_output_hook_to_model(eval_model)\n",
    "_act_handles, activation_signature = attach_relu_activation_hook_to_model(eval_model)\n",
    "\n",
    "logits = eval_model(X)\n",
    "prediction_prob = nn.Softmax(dim=1)(logits)\n",
    "y_pred = prediction_prob.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")\n",
    "\n",
    "print(layer_outputs)\n",
    "print(activation_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80878728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('unsat', {}, <maraboupy.MarabouCore.Statistics at 0x29320feb0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model = create_prophecy_example_model()\n",
    "activation = {1: ['ON', '--'], 3: ['--', '--']}\n",
    "dp(activation, eval_model, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67597514",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
